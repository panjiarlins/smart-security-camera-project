{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPQwrQ80gT4L"
      },
      "outputs": [],
      "source": [
        "# Import all dependencies\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB787mjUDMxz"
      },
      "source": [
        "# **Model Testing Using Camera**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xUCIa9jzKg6"
      },
      "source": [
        "## Load the saved keras model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dip76qmagT4P"
      },
      "outputs": [],
      "source": [
        "model = load_model(os.path.join(os.getcwd(), 'model', 'model_terbaru.h5'), compile=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yoz4q43VLZQ"
      },
      "source": [
        "## Define the output configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDywaONmgT4Q"
      },
      "outputs": [],
      "source": [
        "LABELS = ['bicycle', 'bus', 'car', 'motorbike', 'person']\n",
        "GRID_H, GRID_W = 13, 13\n",
        "ANCHORS = np.array([0.1826925422137672, 0.41441697626638907, 0.07093507577988668, 0.13790057307749862, 0.3710890099560204, 0.6587015133970981, 0.7463448677408963, 0.8127615496823053])\n",
        "ANCHORS[::2], ANCHORS[1::2] = ANCHORS[::2] * GRID_W, ANCHORS[1::2] * GRID_H\n",
        "IMG_HEIGHT, IMG_WIDTH = 416, 416\n",
        "GROUNDTRUTH_BOX = 20\n",
        "obj_threshold = 0.3\n",
        "iou_threshold = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXxhgJyn015O"
      },
      "source": [
        "## Define function for rescaling the model output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDqU_bL3gT4R"
      },
      "outputs": [],
      "source": [
        "class RescaleOutput:\n",
        "    def __init__(self, anchors):\n",
        "        self.anchors = anchors\n",
        "\n",
        "    def fit(self, output):\n",
        "        img_grid_height, img_grid_width, img_box, _ = output.shape\n",
        "        anchors_width, anchors_height = self.anchors[::2], self.anchors[1::2]\n",
        "\n",
        "        arr_img_grid_height = np.zeros_like(output[..., 0])\n",
        "        arr_img_grid_width = np.zeros_like(output[..., 0])\n",
        "        arr_img_anchors_width = np.zeros_like(output[..., 0])\n",
        "        arr_img_anchors_height = np.zeros_like(output[..., 0])\n",
        "\n",
        "        for i in range(img_grid_height):\n",
        "            arr_img_grid_height[i, :, :] = i\n",
        "\n",
        "        for i in range(img_grid_width):\n",
        "            arr_img_grid_width[:, i, :] = i\n",
        "        \n",
        "        for i in range(img_box):\n",
        "            arr_img_anchors_width[:, :, i] = anchors_width[i]\n",
        "\n",
        "        for i in range(img_box):\n",
        "            arr_img_anchors_height[:, :, i] = anchors_height[i]\n",
        "\n",
        "        # rescale x, y, width, height to be in range 0-1\n",
        "        output[..., 0] = (tf.sigmoid(output[..., 0]).numpy() + arr_img_grid_width) / img_grid_width\n",
        "        output[..., 1] = (tf.sigmoid(output[..., 1]).numpy() + arr_img_grid_height) / img_grid_height\n",
        "        output[..., 2] = (np.exp(output[..., 2]) * arr_img_anchors_width) / img_grid_width\n",
        "        output[..., 3] = (np.exp(output[..., 3]) * arr_img_anchors_height) / img_grid_height\n",
        "\n",
        "        # rescale confidence to be in range 0-1\n",
        "        output[..., 4] = tf.sigmoid(output[..., 4]).numpy()\n",
        "\n",
        "        # rescale label probability to be in range 0-1\n",
        "        confidence_expanded = np.expand_dims(output[..., 4], -1)\n",
        "        output[..., 5:] = confidence_expanded * tf.nn.softmax(output[..., 5:], axis=-1).numpy()\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ73wJIzVJe1"
      },
      "source": [
        "## Define class for storing object information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69MU-ZSOgT4Y"
      },
      "outputs": [],
      "source": [
        "class BoundingBox:\n",
        "    def __init__(self, x_min, y_min, x_max, y_max, confidence=None, labels_probability=None):\n",
        "        self.x_min, self.y_min, self.x_max, self.y_max = x_min, y_min, x_max, y_max\n",
        "        self.confidence = confidence\n",
        "        self.set_label(labels_probability)\n",
        "        \n",
        "    def set_label(self, labels_probability):\n",
        "        self.labels_probability = labels_probability\n",
        "        self.label = np.argmax(self.labels_probability)\n",
        "    \n",
        "    def get_label(self):\n",
        "        return self.label\n",
        "    \n",
        "    def get_highest_label_probability_score(self):\n",
        "        return self.labels_probability[self.label]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt_lFcjv1V8T"
      },
      "source": [
        "## Define function to get the image boxes that have probability minimum of obj_treshold\n",
        "by then, we will have multiple boxes for the same object. Therefore, we need to get the boxes which meet the minimum confidence criteria is obj_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_y1azMsgT4Z"
      },
      "outputs": [],
      "source": [
        "def get_image_boxes(rescaled_result, obj_threshold=0.2):\n",
        "    img_grid_height, img_grid_width, img_fitted_anchor, _ = rescaled_result.shape\n",
        "    img_boxes = [] # List of boxes that having confidence > obj_threshold\n",
        "    for row in range(img_grid_height):\n",
        "        for column in range(img_grid_width):\n",
        "            for i in range(img_fitted_anchor):\n",
        "                labels_probability = rescaled_result[row, column, i, 5:]\n",
        "                \n",
        "                if np.sum(labels_probability) > 0:\n",
        "                    center_x, center_y, box_width, box_height = rescaled_result[row, column, i, :4]\n",
        "                    confidence = rescaled_result[row, column, i, 4]\n",
        "                    box = BoundingBox(x_min=center_x - (box_width / 2),\n",
        "                            y_min=center_y - (box_height / 2),\n",
        "                            x_max=center_x + (box_width / 2),\n",
        "                            y_max=center_y + (box_height / 2),\n",
        "                            confidence=confidence,\n",
        "                            labels_probability=labels_probability\n",
        "                        )\n",
        "                    if box.get_highest_label_probability_score() > obj_threshold:\n",
        "                        img_boxes.append(box)\n",
        "\n",
        "    return img_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIRWwNsM175C"
      },
      "source": [
        "## Define function for calculating non-max supression by using IOU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp89crewVJe4"
      },
      "source": [
        "### Define function for calculating IOU between 2 boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7bBSPFdgT4a"
      },
      "outputs": [],
      "source": [
        "class AnchorBoxMatching:\n",
        "  def __init__(self, anchors=None):\n",
        "    if not (anchors is None):\n",
        "      self.anchors = [BoundingBox(0, 0, anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n",
        "  \n",
        "  def _calculate_intersection(self, box1, box2):\n",
        "    x1_box1, x2_box1 = box1\n",
        "    x1_box2, x2_box2 = box2\n",
        "\n",
        "    if x1_box2 < x1_box1:\n",
        "      if x2_box2 < x1_box1: return 0\n",
        "      else: return min(x2_box1, x2_box2) - x1_box1\n",
        "    else:\n",
        "      if x2_box1 < x1_box2: return 0\n",
        "      else: return min(x2_box1, x2_box2) - x1_box2\n",
        "  \n",
        "  def _calculate_box_area(self, box):\n",
        "    box_width = box.x_max - box.x_min\n",
        "    box_height = box.y_max - box.y_min\n",
        "    return box_width * box_height\n",
        "  \n",
        "  def calculate_iou(self, box1, box2):\n",
        "    intersection_width = self._calculate_intersection([box1.x_min, box1.x_max], [box2.x_min, box2.x_max])\n",
        "    intersection_height = self._calculate_intersection([box1.y_min, box1.y_max], [box2.y_min, box2.y_max])\n",
        "    intersection_area = intersection_width * intersection_height\n",
        "\n",
        "    box1_area = self._calculate_box_area(box1)\n",
        "    box2_area = self._calculate_box_area(box2)\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    return float(intersection_area) / union_area\n",
        "  \n",
        "  def fit(self, box_width, box_height):\n",
        "    matched_anchor, max_iou = -1, -1\n",
        "\n",
        "    for anchor_index in range(len(self.anchors)):\n",
        "      iou = self.calculate_iou(BoundingBox(0, 0, box_width, box_height), self.anchors[anchor_index])\n",
        "      if max_iou < iou:\n",
        "        matched_anchor, max_iou = anchor_index, iou\n",
        "\n",
        "    return matched_anchor, max_iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5dDoWd_2ALt"
      },
      "source": [
        "### Define funtion to suppress unwanted boxes that have low probability\n",
        "because there are multiple anchor boxes on a single object, we need to supress the low probability anchor boxes to get the most accurate anchor box to drawn around the detected object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tcH77X7gT4b"
      },
      "outputs": [],
      "source": [
        "def calculate_nonmax_suppression(img_boxes, iou_threshold=0.2, obj_threshold=0.2):\n",
        "    total_boxes = len(img_boxes)\n",
        "    total_label = len(img_boxes[0].labels_probability)\n",
        "    anchorBoxMatching = AnchorBoxMatching()\n",
        "    index_boxes = []\n",
        "    \n",
        "    # suppress non-maximal boxes\n",
        "    for label_index in range(total_label):\n",
        "        all_nth_label_probabilities = [img_box.labels_probability[label_index] for img_box in img_boxes]\n",
        "        box_indices = list(np.argsort(all_nth_label_probabilities)[::-1])\n",
        "\n",
        "        for i in range(total_boxes):\n",
        "            ith_index_of_box_indices = box_indices[i]\n",
        "\n",
        "            if img_boxes[ith_index_of_box_indices].labels_probability[label_index] == 0.: continue\n",
        "            else:\n",
        "                index_boxes.append(ith_index_of_box_indices)\n",
        "                for j in range(i + 1, total_boxes):\n",
        "                    jth_index_of_box_indices = box_indices[j]\n",
        "                    \n",
        "                    iou_i_j = anchorBoxMatching.calculate_iou(img_boxes[ith_index_of_box_indices], img_boxes[jth_index_of_box_indices])\n",
        "                    if iou_i_j > iou_threshold:\n",
        "                        img_boxes[jth_index_of_box_indices].labels_probability[label_index] = 0\n",
        "                        img_boxes[jth_index_of_box_indices].set_label(img_boxes[jth_index_of_box_indices].labels_probability)\n",
        "    \n",
        "    final_img_boxes = []\n",
        "    all_confidence = []\n",
        "    for i in index_boxes:\n",
        "        if img_boxes[i].get_highest_label_probability_score() > obj_threshold:\n",
        "            if img_boxes[i].confidence not in all_confidence:\n",
        "                all_confidence.append(img_boxes[i].confidence)\n",
        "                final_img_boxes.append(img_boxes[i])\n",
        "\n",
        "    return final_img_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2rjezhK2H-s"
      },
      "source": [
        "## Define function to draw boxes on the image\n",
        "\n",
        "We adjust each coordinate point of detected boxes so that those have maximum value is image_width and image_height.\n",
        "The boxes then will be drawn based on those values which is the coordinate for each point in the box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFoaaLqlgT4c"
      },
      "outputs": [],
      "source": [
        "def draw_boxes(image, img_boxes, labels):\n",
        "    image_h, image_w, _ = image.shape\n",
        "    \n",
        "    adjust_boxes = lambda n, nmax: max(min(nmax, n), 0)\n",
        "    color_palette = list([tuple(np.random.choice(range(255), size=3) / 255.) for i in range(8)])\n",
        "    for box, color in zip(img_boxes, color_palette):\n",
        "        x_min = adjust_boxes(int(box.x_min * image_w), image_w)\n",
        "        y_min = adjust_boxes(int(box.y_min * image_h), image_h)\n",
        "        x_max = adjust_boxes(int(box.x_max * image_w), image_w)\n",
        "        y_max = adjust_boxes(int(box.y_max * image_h), image_h)\n",
        "\n",
        "        print(f'{labels[box.label]} {box.get_highest_label_probability_score()} [x_min={x_min}, y_min={y_min}, x_max={x_max}, y_max={y_max}]')\n",
        "        cv2.rectangle(image,\n",
        "                      pt1=(x_min,y_min), \n",
        "                      pt2=(x_max,y_max), \n",
        "                      color=color\n",
        "                      )\n",
        "        cv2.putText(image, \n",
        "                    text=f'{labels[box.label]} {int(box.get_highest_label_probability_score() * 100)}%', \n",
        "                    org=(x_min+ 13, y_min + 13),\n",
        "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    fontScale=1e-3 * image_h,\n",
        "                    color=(1, 0, 1)\n",
        "                    )\n",
        "        \n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SadZXxLJ2LKk"
      },
      "source": [
        "## **Detect using Camera**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BffLltAw2PQV"
      },
      "source": [
        "Code below is to access device's camera. Then the image input will be rezised and normalized for prediction.\n",
        "The model will produce the prediction output then the output will be rescaled and draw the box around the detected object.\n",
        "The output then tells us the label, confidence value, and the coordinate of each point in the box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq74ZVafgT4d"
      },
      "outputs": [],
      "source": [
        "capture = cv2.VideoCapture(0)\n",
        "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 416)\n",
        "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 416)\n",
        "\n",
        "while True:\n",
        "    stime = time.time()\n",
        "    ret, frame = capture.read()\n",
        "    cam_width, cam_height = frame.shape[:2]\n",
        "    if ret:\n",
        "        # Resize image\n",
        "        image = cv2.resize(frame, (IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "        # Normalize image\n",
        "        image = image / 255.\n",
        "\n",
        "        # Model predict\n",
        "        X = np.expand_dims(image, axis=0)\n",
        "        Y = np.zeros((1, 1, 1, 1, GROUNDTRUTH_BOX, 4))\n",
        "        output = model.predict([X, Y])\n",
        "\n",
        "        # Rescale output and Draw the boxes\n",
        "        rescaleOutput = RescaleOutput(ANCHORS)\n",
        "        rescaled_output = rescaleOutput.fit(output[0])\n",
        "        img_boxes = get_image_boxes(rescaled_output, obj_threshold)\n",
        "        if img_boxes:\n",
        "            img_boxes = calculate_nonmax_suppression(img_boxes, iou_threshold, obj_threshold)\n",
        "            frame = draw_boxes(X[0], img_boxes, LABELS)\n",
        "            frame = cv2.resize(frame, (cam_height, cam_width))\n",
        "        \n",
        "        cv2.imshow('frame', frame)\n",
        "        print(f'FPS: {1 / (time.time() - stime)}')\n",
        "    \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "testing.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "9595cffc4dc5d67ea199fccd0f433976018f03e606cb41e110d25c96756cd1c9"
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}