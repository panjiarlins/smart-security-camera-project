{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(os.getcwd(), 'model-groundtruthbox20-anchorboxes[0.37578196, 0.64331881, 0.18122142, 0.38260921, 0.77190043, 0.79726407, 0.06688127, 0.12116184].h5'), compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['bicycle', 'bus', 'car', 'motorbike', 'person']\n",
    "GRID_H, GRID_W = 13, 13\n",
    "ANCHORS = np.array([0.37578196, 0.64331881,\n",
    "                    0.18122142, 0.38260921,\n",
    "                    0.77190043, 0.79726407,\n",
    "                    0.06688127, 0.12116184])\n",
    "ANCHORS[::2], ANCHORS[1::2] = ANCHORS[::2] * GRID_W, ANCHORS[1::2] * GRID_H\n",
    "IMG_HEIGHT, IMG_WIDTH = 416, 416\n",
    "GROUNDTRUTH_BOX = 20\n",
    "obj_threshold = 0.25\n",
    "iou_threshold = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RescaleOutput:\n",
    "    def __init__(self, anchors):\n",
    "        self.anchors = anchors\n",
    "\n",
    "    def fit(self, output):\n",
    "        img_grid_height, img_grid_width, img_box, _ = output.shape\n",
    "        anchors_width, anchors_height = self.anchors[::2], self.anchors[1::2]\n",
    "\n",
    "        arr_img_grid_height = np.zeros_like(output[..., 0])\n",
    "        arr_img_grid_width = np.zeros_like(output[..., 0])\n",
    "        arr_img_anchors_width = np.zeros_like(output[..., 0])\n",
    "        arr_img_anchors_height = np.zeros_like(output[..., 0])\n",
    "\n",
    "        for i in range(img_grid_height):\n",
    "            arr_img_grid_height[i, :, :] = i\n",
    "\n",
    "        for i in range(img_grid_width):\n",
    "            arr_img_grid_width[:, i, :] = i\n",
    "        \n",
    "        for i in range(img_box):\n",
    "            arr_img_anchors_width[:, :, i] = anchors_width[i]\n",
    "\n",
    "        for i in range(img_box):\n",
    "            arr_img_anchors_height[:, :, i] = anchors_height[i]\n",
    "\n",
    "        # rescale x, y, width, height in range 0-1\n",
    "        output[..., 0] = (tf.sigmoid(output[..., 0]).numpy() + arr_img_grid_width) / img_grid_width\n",
    "        output[..., 1] = (tf.sigmoid(output[..., 1]).numpy() + arr_img_grid_height) / img_grid_height\n",
    "        output[..., 2] = (np.exp(output[..., 2]) * arr_img_anchors_width) / img_grid_width\n",
    "        output[..., 3] = (np.exp(output[..., 3]) * arr_img_anchors_height) / img_grid_height\n",
    "\n",
    "        # rescale confidence in range 0-1\n",
    "        output[..., 4]   = tf.sigmoid(output[..., 4]).numpy()\n",
    "\n",
    "        # rescale class probability in range 0-1\n",
    "        confidence_expanded      = np.expand_dims(output[..., 4], -1)\n",
    "        output[..., 5:]  = confidence_expanded * tf.nn.softmax(output[..., 5:], axis=-1).numpy()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBox:\n",
    "    def __init__(self, x_min, y_min, x_max, y_max, confidence=None, labels_probability=None):\n",
    "        self.x_min, self.y_min, self.x_max, self.y_max = x_min, y_min, x_max, y_max\n",
    "        self.confidence = confidence\n",
    "        self.set_label(labels_probability)\n",
    "        \n",
    "    def set_label(self, labels_probability):\n",
    "        self.labels_probability = labels_probability\n",
    "        self.label = np.argmax(self.labels_probability)\n",
    "    \n",
    "    def get_label(self):\n",
    "        return self.label\n",
    "    \n",
    "    def get_highest_label_probability_score(self):\n",
    "        return self.labels_probability[self.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_boxes(rescaled_result, obj_threshold=0.2):\n",
    "    img_grid_height, img_grid_width, img_fitted_anchor, _ = rescaled_result.shape\n",
    "    img_boxes = [] # List of boxes that having confidence > obj_threshold\n",
    "    for row in range(img_grid_height):\n",
    "        for column in range(img_grid_width):\n",
    "            for i in range(img_fitted_anchor):\n",
    "                labels_probability = rescaled_result[row, column, i, 5:]\n",
    "                \n",
    "                if np.sum(labels_probability) > 0:\n",
    "                    center_x, center_y, box_width, box_height = rescaled_result[row, column, i, :4]\n",
    "                    confidence = rescaled_result[row, column, i, 4]\n",
    "                    box = BoundingBox(x_min=center_x - (box_width / 2),\n",
    "                            y_min=center_y - (box_height / 2),\n",
    "                            x_max=center_x + (box_width / 2),\n",
    "                            y_max=center_y + (box_height / 2),\n",
    "                            confidence=confidence,\n",
    "                            labels_probability=labels_probability\n",
    "                        )\n",
    "                    if box.get_highest_label_probability_score() > obj_threshold: img_boxes.append(box)\n",
    "\n",
    "    return img_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBoxMatching:\n",
    "  def __init__(self, anchors=None):\n",
    "    if not (anchors is None):\n",
    "      self.anchors = [BoundingBox(0, 0, anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n",
    "  \n",
    "  def _calculate_intersection(self, box1, box2):\n",
    "    x1_box1, x2_box1 = box1\n",
    "    x1_box2, x2_box2 = box2\n",
    "\n",
    "    if x1_box2 < x1_box1:\n",
    "      if x2_box2 < x1_box1: return 0\n",
    "      else: return min(x2_box1, x2_box2) - x1_box1\n",
    "    else:\n",
    "      if x2_box1 < x1_box2: return 0\n",
    "      else: return min(x2_box1, x2_box2) - x1_box2\n",
    "  \n",
    "  def _calculate_box_area(self, box):\n",
    "    box_width = box.x_max - box.x_min\n",
    "    box_height = box.y_max - box.y_min\n",
    "    return box_width * box_height\n",
    "  \n",
    "  def calculate_iou(self, box1, box2):\n",
    "    intersection_width = self._calculate_intersection([box1.x_min, box1.x_max], [box2.x_min, box2.x_max])\n",
    "    intersection_height = self._calculate_intersection([box1.y_min, box1.y_max], [box2.y_min, box2.y_max])\n",
    "    intersection_area = intersection_width * intersection_height\n",
    "\n",
    "    box1_area = self._calculate_box_area(box1)\n",
    "    box2_area = self._calculate_box_area(box2)\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    return float(intersection_area) / union_area\n",
    "  \n",
    "  def fit(self, box_width, box_height):\n",
    "    matched_anchor, max_iou = -1, -1\n",
    "\n",
    "    for anchor_index in range(len(self.anchors)):\n",
    "      iou = self.calculate_iou(BoundingBox(0, 0, box_width, box_height), self.anchors[anchor_index])\n",
    "      if max_iou < iou: matched_anchor, max_iou = anchor_index, iou\n",
    "\n",
    "    return matched_anchor, max_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nonmax_suppression(img_boxes, iou_threshold=0.2, obj_threshold=0.2):\n",
    "    total_boxes = len(img_boxes)\n",
    "    total_label = len(img_boxes[0].labels_probability)\n",
    "    anchorBoxMatching = AnchorBoxMatching()\n",
    "    index_boxes = []\n",
    "    \n",
    "    # suppress non-maximal boxes\n",
    "    for label_index in range(total_label):\n",
    "        all_nth_label_probabilities = [img_box.labels_probability[label_index] for img_box in img_boxes]\n",
    "        box_indices = list(np.argsort(all_nth_label_probabilities)[::-1])\n",
    "\n",
    "        for i in range(total_boxes):\n",
    "            ith_index_of_box_indices = box_indices[i]\n",
    "\n",
    "            if img_boxes[ith_index_of_box_indices].labels_probability[label_index] == 0.: continue\n",
    "            else:\n",
    "                index_boxes.append(ith_index_of_box_indices)\n",
    "                for j in range(i + 1, total_boxes):\n",
    "                    jth_index_of_box_indices = box_indices[j]\n",
    "                    \n",
    "                    iou_i_j = anchorBoxMatching.calculate_iou(img_boxes[ith_index_of_box_indices], img_boxes[jth_index_of_box_indices])\n",
    "                    if iou_i_j > iou_threshold:\n",
    "                        img_boxes[jth_index_of_box_indices].labels_probability[label_index] = 0\n",
    "                        img_boxes[jth_index_of_box_indices].set_label(img_boxes[jth_index_of_box_indices].labels_probability)\n",
    "    \n",
    "    return [img_boxes[i] for i in index_boxes if img_boxes[i].get_highest_label_probability_score() > obj_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, img_boxes, labels):\n",
    "    image_h, image_w, _ = image.shape\n",
    "    \n",
    "    limit = lambda n, nmax: max(min(nmax, n), 0)\n",
    "    color_palette = list([tuple(np.random.choice(range(255), size=3) / 255.) for i in range(8)])\n",
    "    for box, color in zip(img_boxes, color_palette):\n",
    "        x_min = limit(int(box.x_min * image_w), image_w)\n",
    "        y_min = limit(int(box.y_min * image_h), image_h)\n",
    "        x_max = limit(int(box.x_max * image_w), image_w)\n",
    "        y_max = limit(int(box.y_max * image_h), image_h)\n",
    "\n",
    "        print(f'{labels[box.label]} {int(box.get_highest_label_probability_score() * 100)}% [x_min={x_min}, y_min={y_min}, x_max={x_max}, y_max={y_max}]')\n",
    "        cv2.rectangle(image,\n",
    "                      pt1=(x_min,y_min), \n",
    "                      pt2=(x_max,y_max), \n",
    "                      color=color\n",
    "                      )\n",
    "        cv2.putText(img=image, \n",
    "                    text=f'{labels[box.label]} {int(box.get_highest_label_probability_score() * 100)}%', \n",
    "                    org=(x_min+ 13, y_min + 13),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1e-3 * image_h,\n",
    "                    color=(1, 0, 1)\n",
    "                    )\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 0.5379291434246776\n",
      "FPS: 1.7445526195715966\n",
      "person 26% [x_min=81, y_min=38, x_max=394, y_max=391]\n",
      "person 26% [x_min=81, y_min=38, x_max=394, y_max=391]\n",
      "person 26% [x_min=81, y_min=38, x_max=394, y_max=391]\n",
      "person 26% [x_min=81, y_min=38, x_max=394, y_max=391]\n",
      "person 26% [x_min=81, y_min=38, x_max=394, y_max=391]\n",
      "FPS: 1.555165824129945\n",
      "person 25% [x_min=80, y_min=49, x_max=397, y_max=382]\n",
      "person 25% [x_min=80, y_min=49, x_max=397, y_max=382]\n",
      "person 25% [x_min=80, y_min=49, x_max=397, y_max=382]\n",
      "person 25% [x_min=80, y_min=49, x_max=397, y_max=382]\n",
      "person 25% [x_min=80, y_min=49, x_max=397, y_max=382]\n",
      "FPS: 1.5474555535386718\n",
      "person 46% [x_min=76, y_min=43, x_max=401, y_max=383]\n",
      "person 46% [x_min=76, y_min=43, x_max=401, y_max=383]\n",
      "person 46% [x_min=76, y_min=43, x_max=401, y_max=383]\n",
      "person 46% [x_min=76, y_min=43, x_max=401, y_max=383]\n",
      "person 46% [x_min=76, y_min=43, x_max=401, y_max=383]\n",
      "FPS: 1.605856932882419\n",
      "person 34% [x_min=40, y_min=42, x_max=381, y_max=389]\n",
      "person 34% [x_min=40, y_min=42, x_max=381, y_max=389]\n",
      "person 34% [x_min=40, y_min=42, x_max=381, y_max=389]\n",
      "person 34% [x_min=40, y_min=42, x_max=381, y_max=389]\n",
      "person 34% [x_min=40, y_min=42, x_max=381, y_max=389]\n",
      "FPS: 1.5522535652243425\n",
      "person 35% [x_min=35, y_min=34, x_max=385, y_max=394]\n",
      "person 35% [x_min=35, y_min=34, x_max=385, y_max=394]\n",
      "person 35% [x_min=35, y_min=34, x_max=385, y_max=394]\n",
      "person 35% [x_min=35, y_min=34, x_max=385, y_max=394]\n",
      "person 35% [x_min=35, y_min=34, x_max=385, y_max=394]\n",
      "FPS: 0.6690319821642685\n",
      "person 27% [x_min=83, y_min=34, x_max=392, y_max=390]\n",
      "person 27% [x_min=83, y_min=34, x_max=392, y_max=390]\n",
      "person 27% [x_min=83, y_min=34, x_max=392, y_max=390]\n",
      "person 27% [x_min=83, y_min=34, x_max=392, y_max=390]\n",
      "person 27% [x_min=83, y_min=34, x_max=392, y_max=390]\n",
      "FPS: 1.4564147224036532\n",
      "FPS: 1.5939760130457898\n",
      "person 29% [x_min=34, y_min=29, x_max=386, y_max=394]\n",
      "person 29% [x_min=34, y_min=29, x_max=386, y_max=394]\n",
      "person 29% [x_min=34, y_min=29, x_max=386, y_max=394]\n",
      "person 29% [x_min=34, y_min=29, x_max=386, y_max=394]\n",
      "person 29% [x_min=34, y_min=29, x_max=386, y_max=394]\n",
      "FPS: 1.5675211043159392\n",
      "person 37% [x_min=76, y_min=36, x_max=402, y_max=390]\n",
      "person 37% [x_min=76, y_min=36, x_max=402, y_max=390]\n",
      "person 37% [x_min=76, y_min=36, x_max=402, y_max=390]\n",
      "person 37% [x_min=76, y_min=36, x_max=402, y_max=390]\n",
      "person 37% [x_min=76, y_min=36, x_max=402, y_max=390]\n",
      "FPS: 1.5021325226082494\n",
      "person 49% [x_min=26, y_min=34, x_max=396, y_max=397]\n",
      "person 49% [x_min=26, y_min=34, x_max=396, y_max=397]\n",
      "person 49% [x_min=26, y_min=34, x_max=396, y_max=397]\n",
      "person 49% [x_min=26, y_min=34, x_max=396, y_max=397]\n",
      "person 49% [x_min=26, y_min=34, x_max=396, y_max=397]\n",
      "FPS: 1.5809467880723684\n",
      "person 35% [x_min=83, y_min=47, x_max=394, y_max=383]\n",
      "person 35% [x_min=83, y_min=47, x_max=394, y_max=383]\n",
      "person 35% [x_min=83, y_min=47, x_max=394, y_max=383]\n",
      "person 35% [x_min=83, y_min=47, x_max=394, y_max=383]\n",
      "FPS: 1.5714406676153074\n",
      "person 46% [x_min=35, y_min=29, x_max=385, y_max=399]\n",
      "person 46% [x_min=35, y_min=29, x_max=385, y_max=399]\n",
      "person 46% [x_min=35, y_min=29, x_max=385, y_max=399]\n",
      "person 46% [x_min=35, y_min=29, x_max=385, y_max=399]\n",
      "person 46% [x_min=35, y_min=29, x_max=385, y_max=399]\n",
      "FPS: 1.5591008424258803\n",
      "person 47% [x_min=23, y_min=37, x_max=396, y_max=391]\n",
      "person 47% [x_min=23, y_min=37, x_max=396, y_max=391]\n",
      "person 47% [x_min=23, y_min=37, x_max=396, y_max=391]\n",
      "person 47% [x_min=23, y_min=37, x_max=396, y_max=391]\n",
      "person 47% [x_min=23, y_min=37, x_max=396, y_max=391]\n",
      "FPS: 1.5120711782773588\n",
      "person 49% [x_min=30, y_min=32, x_max=390, y_max=398]\n",
      "person 49% [x_min=30, y_min=32, x_max=390, y_max=398]\n",
      "person 49% [x_min=30, y_min=32, x_max=390, y_max=398]\n",
      "person 49% [x_min=30, y_min=32, x_max=390, y_max=398]\n",
      "person 49% [x_min=30, y_min=32, x_max=390, y_max=398]\n",
      "FPS: 1.4974865185997623\n",
      "person 48% [x_min=22, y_min=34, x_max=399, y_max=395]\n",
      "person 48% [x_min=22, y_min=34, x_max=399, y_max=395]\n",
      "person 48% [x_min=22, y_min=34, x_max=399, y_max=395]\n",
      "person 48% [x_min=22, y_min=34, x_max=399, y_max=395]\n",
      "person 48% [x_min=22, y_min=34, x_max=399, y_max=395]\n",
      "FPS: 1.540447968291255\n",
      "person 41% [x_min=27, y_min=35, x_max=391, y_max=396]\n",
      "person 41% [x_min=27, y_min=35, x_max=391, y_max=396]\n",
      "person 41% [x_min=27, y_min=35, x_max=391, y_max=396]\n",
      "person 41% [x_min=27, y_min=35, x_max=391, y_max=396]\n",
      "person 41% [x_min=27, y_min=35, x_max=391, y_max=396]\n",
      "FPS: 1.552796052022672\n",
      "person 35% [x_min=33, y_min=41, x_max=387, y_max=392]\n",
      "person 35% [x_min=33, y_min=41, x_max=387, y_max=392]\n",
      "person 35% [x_min=33, y_min=41, x_max=387, y_max=392]\n",
      "person 35% [x_min=33, y_min=41, x_max=387, y_max=392]\n",
      "person 35% [x_min=33, y_min=41, x_max=387, y_max=392]\n",
      "FPS: 1.4584317952640913\n",
      "person 32% [x_min=67, y_min=43, x_max=409, y_max=387]\n",
      "FPS: 1.4863725393263045\n",
      "person 43% [x_min=32, y_min=40, x_max=390, y_max=390]\n",
      "person 43% [x_min=32, y_min=40, x_max=390, y_max=390]\n",
      "person 43% [x_min=32, y_min=40, x_max=390, y_max=390]\n",
      "person 43% [x_min=32, y_min=40, x_max=390, y_max=390]\n",
      "person 43% [x_min=32, y_min=40, x_max=390, y_max=390]\n",
      "FPS: 1.5054488704926847\n",
      "person 38% [x_min=28, y_min=43, x_max=393, y_max=389]\n",
      "person 38% [x_min=28, y_min=43, x_max=393, y_max=389]\n",
      "person 38% [x_min=28, y_min=43, x_max=393, y_max=389]\n",
      "person 38% [x_min=28, y_min=43, x_max=393, y_max=389]\n",
      "person 38% [x_min=28, y_min=43, x_max=393, y_max=389]\n",
      "FPS: 1.4278228947096085\n",
      "person 35% [x_min=31, y_min=38, x_max=389, y_max=393]\n",
      "person 35% [x_min=31, y_min=38, x_max=389, y_max=393]\n",
      "person 35% [x_min=31, y_min=38, x_max=389, y_max=393]\n",
      "person 35% [x_min=31, y_min=38, x_max=389, y_max=393]\n",
      "person 35% [x_min=31, y_min=38, x_max=389, y_max=393]\n",
      "FPS: 1.4293030182211\n",
      "person 42% [x_min=32, y_min=37, x_max=387, y_max=391]\n",
      "person 42% [x_min=32, y_min=37, x_max=387, y_max=391]\n",
      "person 42% [x_min=32, y_min=37, x_max=387, y_max=391]\n",
      "person 42% [x_min=32, y_min=37, x_max=387, y_max=391]\n",
      "person 42% [x_min=32, y_min=37, x_max=387, y_max=391]\n",
      "FPS: 1.5009945067725947\n",
      "person 38% [x_min=31, y_min=37, x_max=387, y_max=395]\n",
      "person 38% [x_min=31, y_min=37, x_max=387, y_max=395]\n",
      "person 38% [x_min=31, y_min=37, x_max=387, y_max=395]\n",
      "person 38% [x_min=31, y_min=37, x_max=387, y_max=395]\n",
      "person 38% [x_min=31, y_min=37, x_max=387, y_max=395]\n",
      "FPS: 1.39849011358491\n",
      "person 35% [x_min=36, y_min=36, x_max=382, y_max=397]\n",
      "person 35% [x_min=36, y_min=36, x_max=382, y_max=397]\n",
      "person 35% [x_min=36, y_min=36, x_max=382, y_max=397]\n",
      "person 35% [x_min=36, y_min=36, x_max=382, y_max=397]\n",
      "person 35% [x_min=36, y_min=36, x_max=382, y_max=397]\n",
      "FPS: 1.1526676523450168\n",
      "person 45% [x_min=31, y_min=34, x_max=388, y_max=395]\n",
      "person 45% [x_min=31, y_min=34, x_max=388, y_max=395]\n",
      "person 45% [x_min=31, y_min=34, x_max=388, y_max=395]\n",
      "person 45% [x_min=31, y_min=34, x_max=388, y_max=395]\n",
      "person 45% [x_min=31, y_min=34, x_max=388, y_max=395]\n",
      "FPS: 1.3310099996223683\n",
      "person 32% [x_min=32, y_min=29, x_max=388, y_max=401]\n",
      "person 32% [x_min=32, y_min=29, x_max=388, y_max=401]\n",
      "person 32% [x_min=32, y_min=29, x_max=388, y_max=401]\n",
      "person 32% [x_min=32, y_min=29, x_max=388, y_max=401]\n",
      "person 32% [x_min=32, y_min=29, x_max=388, y_max=401]\n",
      "FPS: 1.30214941531706\n",
      "person 36% [x_min=23, y_min=35, x_max=398, y_max=396]\n",
      "person 36% [x_min=23, y_min=35, x_max=398, y_max=396]\n",
      "person 36% [x_min=23, y_min=35, x_max=398, y_max=396]\n",
      "person 36% [x_min=23, y_min=35, x_max=398, y_max=396]\n",
      "person 36% [x_min=23, y_min=35, x_max=398, y_max=396]\n",
      "FPS: 1.2335324762560738\n",
      "person 37% [x_min=29, y_min=33, x_max=392, y_max=395]\n",
      "person 37% [x_min=29, y_min=33, x_max=392, y_max=395]\n",
      "person 37% [x_min=29, y_min=33, x_max=392, y_max=395]\n",
      "person 37% [x_min=29, y_min=33, x_max=392, y_max=395]\n",
      "FPS: 1.2164045525150546\n",
      "person 31% [x_min=35, y_min=33, x_max=386, y_max=390]\n",
      "person 31% [x_min=35, y_min=33, x_max=386, y_max=390]\n",
      "person 31% [x_min=35, y_min=33, x_max=386, y_max=390]\n",
      "FPS: 1.3431288599346864\n",
      "FPS: 1.4021554320725993\n",
      "person 39% [x_min=35, y_min=29, x_max=384, y_max=397]\n",
      "person 39% [x_min=35, y_min=29, x_max=384, y_max=397]\n",
      "person 39% [x_min=35, y_min=29, x_max=384, y_max=397]\n",
      "person 39% [x_min=35, y_min=29, x_max=384, y_max=397]\n",
      "person 39% [x_min=35, y_min=29, x_max=384, y_max=397]\n",
      "FPS: 1.4172560208741207\n",
      "person 53% [x_min=36, y_min=35, x_max=382, y_max=395]\n",
      "person 53% [x_min=36, y_min=35, x_max=382, y_max=395]\n",
      "person 53% [x_min=36, y_min=35, x_max=382, y_max=395]\n",
      "FPS: 1.3016955885524883\n",
      "person 55% [x_min=28, y_min=34, x_max=390, y_max=397]\n",
      "person 55% [x_min=28, y_min=34, x_max=390, y_max=397]\n",
      "person 55% [x_min=28, y_min=34, x_max=390, y_max=397]\n",
      "person 55% [x_min=28, y_min=34, x_max=390, y_max=397]\n",
      "FPS: 1.2776060482372507\n",
      "person 57% [x_min=26, y_min=31, x_max=393, y_max=401]\n",
      "person 57% [x_min=26, y_min=31, x_max=393, y_max=401]\n",
      "FPS: 1.2056879972312005\n",
      "person 65% [x_min=24, y_min=13, x_max=395, y_max=413]\n",
      "FPS: 1.387817145678143\n",
      "person 64% [x_min=30, y_min=11, x_max=386, y_max=413]\n",
      "FPS: 1.2074063860086883\n",
      "person 64% [x_min=22, y_min=10, x_max=392, y_max=413]\n",
      "FPS: 1.2152591176942695\n",
      "person 35% [x_min=25, y_min=59, x_max=395, y_max=409]\n",
      "FPS: 1.227817386378772\n",
      "FPS: 1.2157381755278107\n",
      "FPS: 1.2983547935350703\n",
      "FPS: 1.2010901236254257\n",
      "FPS: 1.2580041234590267\n",
      "FPS: 1.366073734625049\n",
      "FPS: 1.3135400062008125\n",
      "FPS: 1.2958293015386935\n",
      "FPS: 1.2529709600067156\n",
      "FPS: 1.3202684288276116\n",
      "FPS: 0.5212765203821871\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 416)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 416)\n",
    "\n",
    "while True:\n",
    "    stime = time.time()\n",
    "    ret, frame = capture.read()\n",
    "    cam_width, cam_height = frame.shape[:2]\n",
    "    if ret:\n",
    "        # Resize image\n",
    "        image = cv2.resize(frame, (IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "        # Normalize image\n",
    "        image = image / 255.\n",
    "\n",
    "        # Model predict\n",
    "        X = np.expand_dims(image, axis=0)\n",
    "        Y = np.zeros((1, 1, 1, 1, GROUNDTRUTH_BOX, 4))\n",
    "        results = model.predict([X, Y])\n",
    "\n",
    "        # Rescale output and Draw the boxes\n",
    "        rescaleResult = RescaleOutput(ANCHORS)\n",
    "        rescaled_result = rescaleResult.fit(results[0])\n",
    "        img_boxes = get_image_boxes(rescaled_result, obj_threshold)\n",
    "        if img_boxes:\n",
    "            img_boxes = calculate_nonmax_suppression(img_boxes, iou_threshold, obj_threshold)\n",
    "            frame = draw_boxes(X[0], img_boxes, LABELS)\n",
    "            frame = cv2.resize(frame, (cam_height, cam_width))\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "        print(f'FPS: {1 / (time.time() - stime)}')\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9595cffc4dc5d67ea199fccd0f433976018f03e606cb41e110d25c96756cd1c9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
